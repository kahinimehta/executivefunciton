{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script merges cleaned data from an old data freeze, with new data pulled from Axis.\n",
    "#Inputs:\n",
    "    #enrollment sheets pulled from AXIS, stored at afp://saturn/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/inputs\n",
    "    #data cleaned and organized from 2020, stored at afp://saturn/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/flywheel_data_uploads/data_ready_for_upload/\n",
    "    #log of redcap IDs pulled from AXIS (https://axis.med.upenn.edu/redcap_v10.3.7/DataExport/index.php?pid=378&report_id=2598) and stored at afp://saturn/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/inputs\n",
    "    #new data pulled from AXIS (https://axis.med.upenn.edu/redcap_v10.3.7/DataExport/index.php?pid=191&report_id=1331) and stored at afp://saturn/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/inputs\n",
    "#Outputs:\n",
    "    #a csv of all pre-scan scales collected for participants enrolled prior to April 1st, 2022 \n",
    "    #a csv of all post-scan scales collected for participants enrolled prior to April 1st, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in T1 enrollment\n",
    "axis_t1=pd.read_csv('/Volumes/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/inputs/axis_enroll_t1.csv',dtype=str)\n",
    "axis_t1=axis_t1.drop(columns=['scan_1_date'])\n",
    "#axis_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat \n",
    "t1_enroll=axis_t1['bblid']\n",
    "t1_enroll=t1_enroll.tolist()\n",
    "t1_enroll = [str(t) for t in t1_enroll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in RedCAP IDS from EF tracker\n",
    "redcap_ids = pd.read_csv('/Volumes/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/inputs/axis_redcap_ids.csv', dtype=str)\n",
    "prescan_ids = redcap_ids['prescan_redcap_id']\n",
    "prescan_ids = prescan_ids.tolist()\n",
    "prescan_ids = [str(i) for i in prescan_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['345', '276', '279', '455', '287', '290', '464', '386', '611', '415', '377', '841', '475', '471', '694', '420', '769', '607', '603', '499', '599', '503', '507', '479', '429', '550', '484', '641', '517', '619', '615', '661', '629', '670', '741', '779', '761', '717', '867', '805', '1004', '857', '852', '885', '918', '990', '1025', '950', '967', '1127', '1131', '994', '1092', '1099', '1045', '1055', '1114', '1110', '1069', '1073', '1081', '1177', '1266', '1271', '1170', '1235', '1293', '1185', '1246', '1345', '1341', '1262', '1305', '1333', '1356', '1370', '1461', '1422', '1481', '1447', '2030', '1385', '1526', '2349', '2019', '1539', '2778', '1831', '2026', '3107', '2281', '2443', '2704', '2495', '3096', '3222', '2811', '3044', '3200', '3204', '2918', '3040', '2945', '2922', '3089', '3301', '3305', '1391812379', '3379', '3337', '3488', '3491', '3925', '3989', '3981', '4384', '4214', '4267', '4324', '4328', '4414', '4423', '4271', '1778']\n"
     ]
    }
   ],
   "source": [
    "#get rid of nan's\n",
    "prescan_ids1=[]\n",
    "for s in prescan_ids:\n",
    "    if 'nan' not in s:\n",
    "        #t=s.split('.')[0]\n",
    "        #print(t)\n",
    "        prescan_ids1.append(s)\n",
    "print(prescan_ids1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in raw SR data\n",
    "sr=pd.read_csv('/Volumes/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/inputs/axis_EF_pre_post_scan_scales.csv',dtype=str) \n",
    "#filter for scale IDs from RedCAP \n",
    "pre_scan=sr[sr['scales_id'].isin(prescan_ids1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in pre scan cleaned SR data from last audit/freeze, and get list of IDs\n",
    "pre_cleaned=pd.read_csv('/Volumes/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/flywheel_data_uploads/data_ready_for_upload/EF_pre_scan_scales_CLEANED.csv', dtype=str)\n",
    "cleaned_ids = pre_cleaned['scales_id']\n",
    "cleaned_ids = cleaned_ids.tolist()\n",
    "cleaned_ids = [str(i) for i in cleaned_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2030', '2349', '2019', '2778', '1831', '2026', '3107', '2281', '2443', '2704', '2495', '3096', '3222', '2811', '3044', '3200', '3204', '2918', '3040', '2945', '2922', '3089', '3301', '3305', '1391812379', '3379', '3337', '3488', '3491', '3925', '3989', '3981', '4384', '4214', '4267', '4324', '4328', '4414', '4423', '4271', '1778']\n"
     ]
    }
   ],
   "source": [
    "#find which id's were not included in last data freeze \n",
    "missing=[]\n",
    "for i in prescan_ids1:\n",
    "    if i  not in cleaned_ids:\n",
    "        missing.append(i)\n",
    "\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out any data that was already organized in the last audit. \n",
    "new = pre_scan[pre_scan['scales_id'].isin(missing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any columns that identifiers, or are not necessary for EF \n",
    "new=new.drop(columns=['date'])\n",
    "new=new.drop(columns=['admin_proband'])\n",
    "new=new.drop(columns=['admin_proband_group'])\n",
    "new=new.drop(columns=['admin_motive_timepoint'])\n",
    "\n",
    "pre_cleaned=pre_cleaned.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_scan_t1 = pd.concat([pre_cleaned, new], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a \"timepoint\" variable (this is t1) and merge with scan IDs so data is easily used w BIDS \n",
    "t1_pre_scan=pd.merge(pre_scan_t1,axis_t1, left_on=\"bblid\", right_on=\"bblid\")\n",
    "t1_pre_scan=t1_pre_scan.rename(columns={\"scan_id_timepoint_1\": \"scan_id\"})\n",
    "t1_pre_scan['timepoint']= '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in T2 enrollment\n",
    "axis_t2=pd.read_csv('/Volumes/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/inputs/axis_enroll_t2.csv',dtype=str)\n",
    "axis_t2=axis_t2.drop(columns=['scan_2_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat \n",
    "t2_enroll=axis_t2['bblid']\n",
    "t2_enroll=t2_enroll.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get redcap IDs for pre-scan T2\n",
    "prescan_ids_t2 = redcap_ids['prescan_redcap_id_t2']\n",
    "prescan_ids_t2 = prescan_ids_t2.tolist()\n",
    "prescan_ids_t2 = [str(i) for i in prescan_ids_t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2469', '3232', '2120', '2473', '2220', '2209', '3196', '2185', '2189', '2322', '2598', '2477', '2318', '4389', '2602', '2873', '3018', '2664', '2649', '2771', '3457', '3461', '3254', '3855', '4151', '4056', '3526', '4300', '1391812360', '3516', '4292', '3756', '4204', '4480', '4521']\n"
     ]
    }
   ],
   "source": [
    "#get rid of nan's\n",
    "prescan_ids2=[]\n",
    "for s in prescan_ids_t2:\n",
    "    if 'nan' not in s:\n",
    "        #t=s.split('.')[0]\n",
    "        #print(t)\n",
    "        prescan_ids2.append(s)\n",
    "print(prescan_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_scan2=sr[sr['scales_id'].isin(prescan_ids2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_scan2=pre_scan2.drop(columns=['date'])\n",
    "pre_scan2=pre_scan2.drop(columns=['admin_proband'])\n",
    "pre_scan2=pre_scan2.drop(columns=['admin_proband_group'])\n",
    "pre_scan2=pre_scan2.drop(columns=['admin_motive_timepoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a \"timepoint\" variable (this is t2) and merge with scan IDs so data is easily used w BIDS \n",
    "t2_pre_scan=pd.merge(pre_scan2,axis_t2, left_on=\"bblid\", right_on=\"bblid\")\n",
    "t2_pre_scan=t2_pre_scan.rename(columns={\"scan_id_t2\": \"scan_id\"})\n",
    "t2_pre_scan['timepoint']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#altogether now! \n",
    "all_pre_scan = pd.concat([t1_pre_scan, t2_pre_scan], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pre_scan.to_csv('/Volumes/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/outputs/EF_all_prescan_scales.csv', sep = ',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and for post scan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1\n",
    "postscan_ids = redcap_ids['postscan_redcap_id']\n",
    "postscan_ids = postscan_ids.tolist()\n",
    "postscan_ids = [str(i) for i in postscan_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['346', '277', '288', '291', '465', '612', '416', '378', '842', '476', '472', '695', '421', '770', '608', '604', '500', '600', '504', '508', '480', '430', '551', '485', '518', '620', '616', '671', '742', '780', '762', '868', '806', '1005', '858', '853', '886', '891', '991', '1026', '968', '1128', '1132', '995', '1093', '1100', '1046', '1056', '1115', '1111', '1070', '1074', '1078', '1178', '1267', '1272', '1171', '1236', '1294', '1186', '1247', '1346', '1263', '1306', '1334', '1357', '1371', '1462', '1423', '1482', '2031', '1448', '1386', '2350', '2020', '1527', '2779', '1540', '1832', '2027', '3108', '2282', '2444', '2705', '2496', '3097', '3223', '2812', '3045', '3201', '3205', '2919', '3041', '2946', '2923', '3090', '3302', '3306', '1391812380', '3380', '3338', '3499', '3492', '3926', '3990', '3982', '4385', '4215', '4268', '4325', '4329', '4415', '4424', '4272', '1779']\n"
     ]
    }
   ],
   "source": [
    "#get rid of nan's\n",
    "postscan_ids1=[]\n",
    "for s in postscan_ids:\n",
    "    if 'nan' not in s:\n",
    "        #t=s.split('.')[0]\n",
    "        #print(t)\n",
    "        postscan_ids1.append(s)\n",
    "print(postscan_ids1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_scan=sr[sr['scales_id'].isin(postscan_ids1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in pre scan cleaned SR data from last time, and get list of IDs\n",
    "post_cleaned=pd.read_csv('/Volumes/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/flywheel_data_uploads/data_ready_for_upload/EF_post_scan_scales_CLEANED.csv', dtype=str)\n",
    "cleaned_ids = post_cleaned['scales_id']\n",
    "cleaned_ids = cleaned_ids.tolist()\n",
    "cleaned_ids = [str(i) for i in cleaned_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['277', '2031', '2350', '2020', '2779', '1832', '2027', '3108', '2282', '2444', '2705', '2496', '3097', '3223', '2812', '3045', '3201', '3205', '2919', '3041', '2946', '2923', '3090', '3302', '3306', '1391812380', '3380', '3338', '3499', '3492', '3926', '3990', '3982', '4385', '4215', '4268', '4325', '4329', '4415', '4424', '4272', '1779']\n"
     ]
    }
   ],
   "source": [
    "missing=[]\n",
    "for i in postscan_ids1:\n",
    "    if i  not in cleaned_ids:\n",
    "        missing.append(i)\n",
    "\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out any data that was already organized in the last audit. \n",
    "new2 = post_scan[post_scan['scales_id'].isin(missing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2=new2.drop(columns=['date'])\n",
    "new2=new2.drop(columns=['admin_proband'])\n",
    "new2=new2.drop(columns=['admin_proband_group'])\n",
    "new2=new2.drop(columns=['admin_motive_timepoint'])\n",
    "\n",
    "post_cleaned=post_cleaned.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_scan_t1 = pd.concat([post_cleaned, new2], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a \"timepoint\" variable (this is t1) and merge with scan IDs so data is easily used w BIDS \n",
    "t1_post_scan=pd.merge(post_scan_t1,axis_t1, left_on=\"bblid\", right_on=\"bblid\")\n",
    "t1_post_scan=t1_post_scan.rename(columns={\"scan_id_timepoint_1\": \"scan_id\"})\n",
    "t1_post_scan['timepoint']= '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get redcap IDs for pre-scan T2\n",
    "postscan_ids_t2 = redcap_ids['postscan_redcap_id_t2']\n",
    "postscan_ids_t2 = postscan_ids_t2.tolist()\n",
    "postscan_ids_t2 = [str(i) for i in postscan_ids_t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2470', '3233', '2121', '2474', '2221', '2210', '3197', '2186', '2190', '2323', '2599', '2478', '2319', '4390', '2603', '2874', '3019', '2665', '2650', '3458', '3462', '3255', '3856', '4152', '4057', '3527', '4301', '1391812361', '3517', '4293', '3757', '4205', '4481', '4522']\n"
     ]
    }
   ],
   "source": [
    "#get rid of nan's\n",
    "postscan_ids2=[]\n",
    "for s in postscan_ids_t2:\n",
    "    if 'nan' not in s:\n",
    "        #t=s.split('.')[0]\n",
    "        #print(t)\n",
    "        postscan_ids2.append(s)\n",
    "print(postscan_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_scan2=sr[sr['scales_id'].isin(postscan_ids2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_scan2=post_scan2.drop(columns=['date'])\n",
    "post_scan2=post_scan2.drop(columns=['admin_proband'])\n",
    "post_scan2=post_scan2.drop(columns=['admin_proband_group'])\n",
    "post_scan2=post_scan2.drop(columns=['admin_motive_timepoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a \"timepoint\" variable (this is t2) and merge with scan IDs so data is easily used w BIDS \n",
    "t2_post_scan=pd.merge(post_scan2,axis_t2, left_on=\"bblid\", right_on=\"bblid\")\n",
    "t2_post_scan=t2_post_scan.rename(columns={\"scan_id_t2\": \"scan_id\"})\n",
    "t2_post_scan['timepoint']= '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#altogether now! \n",
    "all_post_scan = pd.concat([t1_post_scan, t2_post_scan], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_post_scan.to_csv('/Volumes/Coordinators/Protocols/TED_PROTOCOLS/EXECUTIVE_829744/2022_data_freeze/outputs/EF_all_postscan_scales.csv', sep = ',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
